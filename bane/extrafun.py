import cgi,requests,os,random,re,hashlib,urllib,sys,cfscrape,json,gc
from googlesearch import search
from bane.payloads import ua
from bane.hasher import *
if  sys.version_info < (3,0):
    import HTMLParser
else:
    import html.parser as HTMLParser
import bs4
from bs4 import BeautifulSoup
from bane.payloads import *
from bane.pager import crawl

def clear_file(w):
 with open(w,'w'):
     pass
 f.close()


def get_current_instances(instance_type):
 active=[]
 inactive=[]
 b=list(gc.get_objects())
 for x in b:
  try:
   if 'bane.'+instance_type in x.__repr__():
    try:
     if x.done()==True:
      inactive.append(x)
     else:
      active.append(x)
    except:
     pass
  except:
   pass 
 return {"active":active,"inactive":inactive}


def delete_file(w):
 if os.path.exists(w):
  os.remove(w)

def write_file(w,fi,encode="utf-8"):
    with open(fi ,"a+",encoding=encode) as f:
        f.write(w+'\n')
    f.close()
def read_file(w):
    with open(w ,"r") as f:
        l= f.readlines()
    f.close()
    return l

def create_file(w):
    with open(w ,"a+") as f:
     pass
    f.close()

def get_cf_cookie(domain,user_agent):
  try:
   s = cfscrape.create_scraper()
   c = s.get_cookie_string("http://"+domain,user_agent=user_agent)
   return c[0]
  except:
   return {}

def HTB_invitation():
 try:
  r=requests.post('https://www.hackthebox.eu/api/invite/generate',headers={'User-Agent':random.choice(ua)},data={'':''}).text
  a=r.split('"code":"')[1].split('"')[0]
  return base64_decode(a)
 except:
  return None

def facebook_id(u,tries=10):
 try:
  r=requests.post('https://lookup-id.com/#',data={"fburl":u,"check":"Lookup"}).text
  fb_id= r.split('<p id="code-wrap"><span id="code">')[1].split('<')[0]
  name=r.split('<p id="success"><b>Success!</b> If Facebook name is <em>')[1].split('</em>')[0]
  return(int(fb_id),name)
 except:
  if tries==0:
   return None
  return facebook_id(u,tries=tries-1)


def google_dorking(q,max_results=100,language='en',start_from=1, stop_on=None,top_level_domain='com',pause=2):
 j=[]
 j+=search(q,num=max_results,lang=language,start=start_from, stop=stop_on,tld="com", pause=2)
 l=[]
 for x in j:
  if x not in l:
   l.append(x)
 return l

def escape_html(s):
 '''
   function to return escaped html string
 '''
 return cgi.escape(s,quote=True)

def unescape_html(s):
 '''
   function to return unescaped html string
 '''
 return HTMLParser.HTMLParser().unescape(s).encode("utf-8")

def webhint_report(ur,proxy=None,timeout=10):
 '''
   this function takes any webpage link and returns a report link from webhint.io.
'''
 u="https://webhint.io/scanner/"
 if proxy:
  proxy={'http':'http://'+proxy}
 r=''
 if ("://" not in ur):
  return r
 try:
  s=requests.session()
  s.get(u,proxies=proxy,timeout=timeout)
  data={"url":ur}
  a=s.post(u, data,proxies=proxy,timeout=timeout).text
  soup=BeautifulSoup(a, "html.parser")
  s=soup.find_all("span", class_="permalink-content")
  for x in s:
   try:
    r= x.a["href"]
   except Exception as ex:
    pass
 except Exception as e:
  pass
 return r

def youtube_search(q,proxy=None,timeout=10):
 '''
   this function is for searching on youtub and returning a links of related videos.
'''
 q=q.replace(" ","+")
 u="https://www.youtube.com/results"
 params={"search_query":q}
 l=[]
 try:
  r=requests.get(u,params,headers = {'User-Agent': random.choice(ua)},proxies=proxy,timeout=timeout).text
  soup=BeautifulSoup(r,"html.parser")
  yt = soup.find_all(attrs={'class':'yt-uix-tile-link'})
  for vi in yt:
   try:
    vi="https://www.youtube.com"+str(vi['href'])
    if (vi not in l):
     l.append(vi)
   except Exception as ex:
    pass
 except Exception as e:
  pass
 return l

def webcams(count=10,by={'country':'us'},timeout=10):
 a=0
 f={}
 x=1
 if by:
  key=list(by.keys())[0]
  if key not in ['country','tag','city','timezone','type']:
   raise Exception('Your search must be in one of these categories: country, city, timezone, type, tag')
  value=by[key].lower()
  if 'country' in by:
   if by['country'].lower() not in ['af', 'ax', 'al', 'dz', 'as', 'ad', 'ao', 'ai', 'aq', 'ag', 'ar', 'am', 'aw', 'au', 'at', 'az', 'bs', 'bh', 'bd', 'bb', 'by', 'be', 'bz', 'bj', 'bm', 'bt', 'bo', 'bq', 'ba', 'bw', 'br', 'io', 'bn', 'bg', 'bf', 'bi', 'cv', 'kh', 'cm', 'ca', 'ky', 'cf', 'td', 'cl', 'cn', 'cx', 'cc', 'co', 'km', 'cd', 'cg', 'ck', 'cr', 'ci', 'hr', 'cu', 'cw', 'cy', 'cz', 'dk', 'dj', 'dm', 'do', 'ec', 'eg', 'sv', 'gq', 'er', 'ee', 'sz', 'et', 'fk', 'fo', 'fj', 'fi', 'fr', 'gf', 'pf', 'tf', 'ga', 'gm', 'ge', 'de', 'gh', 'gi', 'gr', 'gl', 'gd', 'gp', 'gu', 'gt', 'gg', 'gn', 'gw', 'gy', 'ht', 'hm', 'va', 'hn', 'hk', 'hu', 'is', 'in', 'id', 'ir', 'iq', 'ie', 'im', 'il', 'it', 'jm', 'jp', 'je', 'jo', 'kz', 'ke', 'ki', 'kp', 'kr', 'kw', 'kg', 'la', 'lv', 'lb', 'ls', 'lr', 'ly', 'li', 'lt', 'lu', 'mo', 'mk', 'mg', 'mw', 'my', 'mv', 'ml', 'mt', 'mh', 'mq', 'mr', 'mu', 'yt', 'mx', 'fm', 'md', 'mc', 'mn', 'me', 'ms', 'ma', 'mz', 'mm', 'na', 'nr', 'np', 'nl', 'nc', 'nz', 'ni', 'ne', 'ng', 'nu', 'nf', 'mp', 'no', 'om', 'pk', 'pw', 'ps', 'pa', 'pg', 'py', 'pe', 'ph', 'pn', 'pl', 'pt', 'pr', 'qa', 're', 'ro', 'ru', 'rw', 'bl', 'sh', 'kn', 'lc', 'mf', 'pm', 'vc', 'ws', 'sm', 'st', 'sa', 'sn', 'rs', 'sc', 'sl', 'sg', 'sx', 'sk', 'si', 'sb', 'so', 'za', 'gs', 'ss', 'es', 'lk', 'sd', 'sr', 'se', 'ch', 'sy', 'tw', 'tj', 'tz', 'th', 'tl', 'tg', 'tk', 'to', 'tt', 'tn', 'tr', 'tm', 'tc', 'tv', 'ug', 'ua', 'ae', 'gb', 'us', 'uy', 'uz', 'vu', 've', 'vn', 'vg', 'vi', 'wf', 'ye', 'zm', 'zw']:
    raise Exception('Unexisting Country code')
  url="https://www.insecam.org/en/by{}/{}/?page=".format(key,value)
 else:
  url="https://www.insecam.org/en/byrating/?page="
 while True:
  try:
   soup = BeautifulSoup(requests.get(url+str(x), headers={'User-Agent': random.choice(ua)},timeout=timeout).text,"html.parser")
   fi = soup.findAll('img',{'class':'thumbnail-item__img img-responsive'})
   for i in fi:
    j=HTMLParser.HTMLParser().unescape(i['src'])
    o=HTMLParser.HTMLParser().unescape(i['title'])
    f.update({j:o})
   if (len(fi)==0 ) or (a==len(f)):
    break
   a=len(f)
  except Exception as e:
   break
  if len(f)>=int(count):
    break
  x+=1
 return {k: f[k] for k in list(f.keys())[:int(count)]}
